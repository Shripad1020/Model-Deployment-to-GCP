{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq4kxIpQMpZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cfd592c-e916-40a2-f31d-d080702e56b5"
      },
      "source": [
        "#Hardware accelerator: GPU\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuEt72UJoWEd",
        "outputId": "eae6fdbc-26b3-4e61-db9f-8e8c8a6a4023"
      },
      "source": [
        "!pwd\n",
        "%cd /content/drive/MyDrive/kaggle"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/kaggle\n",
            "/content/drive/MyDrive/kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9IdsOGuLYVK"
      },
      "source": [
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_1Ol5LZXrb8"
      },
      "source": [
        "# Setup data inputs\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "def create_data_loaders(train_dir, test_dir, image_size=IMG_SIZE):\n",
        "  train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                  label_mode=\"categorical\",\n",
        "                                                                  image_size=image_size)\n",
        "\n",
        "  test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                  label_mode=\"categorical\",\n",
        "                                                                  image_size=image_size)\n",
        "  \n",
        "  return train_data, test_data"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Icsoq0YYRb"
      },
      "source": [
        "# Create a data augmentation stage with horizontal flipping, rotations, zooms\n",
        "data_augmentation = keras.Sequential([\n",
        "  preprocessing.RandomFlip(\"horizontal\"),\n",
        "  preprocessing.RandomRotation(0.2),\n",
        "  preprocessing.RandomZoom(0.2),\n",
        "  preprocessing.RandomHeight(0.2),\n",
        "  preprocessing.RandomWidth(0.2),\n",
        "  # preprocessing.Rescaling(1./255) # keep for ResNet50V2, remove for EfficientNetB0\n",
        "], name =\"data_augmentation\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn5qDRF8XqLs",
        "outputId": "71bf1f7c-fbaa-4db0-90a6-1bae554b3431"
      },
      "source": [
        "# Setup input shape and base model, freezing the base model layers\n",
        "INPUT_SHAPE = (224, 224, 3)\n",
        "BASE_MODEL = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "\n",
        "def create_model(input_shape=INPUT_SHAPE, base_model=BASE_MODEL, num_classes=10):\n",
        "  base_model.trainable = False\n",
        "\n",
        "  # Create input layer\n",
        "  inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
        "\n",
        "  # Add in data augmentation Sequential model as a layer\n",
        "  x = data_augmentation(inputs)\n",
        "\n",
        "  # Give base_model inputs (after augmentation) and don't train it\n",
        "  x = base_model(x, training=False)\n",
        "\n",
        "  # Pool output features of base model\n",
        "  x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
        "\n",
        "  # Put a dense layer on as the output\n",
        "  outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\")(x)\n",
        "\n",
        "  # Make a model with inputs and outputs\n",
        "  model = keras.Model(inputs, outputs)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5w0PI1pOl7I"
      },
      "source": [
        "# Create a function to import an image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224, scale=False):\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode it into a tensor\n",
        "  img = tf.image.decode_jpeg(img)\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, [img_shape, img_shape])\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  if scale:\n",
        "    return img/255.\n",
        "  else:\n",
        "    return img"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIOp96x5gN-u"
      },
      "source": [
        "# Unzip the downloaded file\n",
        "def unzip_data(filename):\n",
        "  zip_ref = zipfile.ZipFile(filename, \"r\")\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwWwP657Szfv"
      },
      "source": [
        "# Get data\n",
        "import zipfile\n",
        "unzip_data(\"10_food_classes_all_data.zip\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yamhJ8xJA5x"
      },
      "source": [
        "import datetime\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mXArGOXXn6P"
      },
      "source": [
        "## Model 1 (10 classes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwrIl-rsLdz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77a1f37-d4b9-4bcb-c2e1-56e863764fd0"
      },
      "source": [
        "# Create BatchDataset\n",
        "train_data, test_data = create_data_loaders(train_dir=\"10_food_classes_all_data/train/\",\n",
        "                                            test_dir=\"10_food_classes_all_data/test/\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7500 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_h12Aozqge7",
        "outputId": "264fc1f4-c270-43eb-94e7-779c12e03605"
      },
      "source": [
        "train_data"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 224, 224, 3), (None, 10)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSo9wTmBy6zr",
        "outputId": "a7196ecb-b97f-490e-9248-5118f59d0038"
      },
      "source": [
        "# Create model\n",
        "model_1 = create_model(num_classes=len(train_data.class_names))\n",
        "\n",
        "# Fit the model\n",
        "history_1_percent = model_1.fit(train_data,\n",
        "                    epochs=5,\n",
        "                    steps_per_epoch=len(train_data),\n",
        "                    validation_data=test_data,\n",
        "                    validation_steps=int(0.25 * len(test_data)), # validate for less steps\n",
        "                    # Track model training logs\n",
        "                    callbacks=[create_tensorboard_callback(\"transfer_learning\", \"all_data_aug\")])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: transfer_learning/all_data_aug/20210427-144442\n",
            "Epoch 1/5\n",
            "235/235 [==============================] - 172s 581ms/step - loss: 1.4528 - accuracy: 0.5444 - val_loss: 0.5686 - val_accuracy: 0.8421\n",
            "Epoch 2/5\n",
            "235/235 [==============================] - 108s 455ms/step - loss: 0.7062 - accuracy: 0.7863 - val_loss: 0.4615 - val_accuracy: 0.8651\n",
            "Epoch 3/5\n",
            "235/235 [==============================] - 101s 426ms/step - loss: 0.6157 - accuracy: 0.8110 - val_loss: 0.4649 - val_accuracy: 0.8454\n",
            "Epoch 4/5\n",
            "235/235 [==============================] - 95s 402ms/step - loss: 0.5625 - accuracy: 0.8256 - val_loss: 0.4580 - val_accuracy: 0.8520\n",
            "Epoch 5/5\n",
            "235/235 [==============================] - 90s 381ms/step - loss: 0.5257 - accuracy: 0.8375 - val_loss: 0.4449 - val_accuracy: 0.8635\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUKJxKVaY3aA",
        "outputId": "b5672563-791f-47d5-b2ec-4e55e5d8d1fd"
      },
      "source": [
        "# Get an image Tensor\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-27 15:28:00--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2874848 (2.7M) [image/jpeg]\n",
            "Saving to: ‘03-pizza-dad.jpeg’\n",
            "\n",
            "03-pizza-dad.jpeg   100%[===================>]   2.74M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-04-27 15:28:01 (24.1 MB/s) - ‘03-pizza-dad.jpeg’ saved [2874848/2874848]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3SwO_LAqHAM",
        "outputId": "34196542-5c95-4308-9e5b-68d052ebc559"
      },
      "source": [
        "# Classes our model is trained on\n",
        "class_names = train_data.class_names\n",
        "class_names"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7gCXuavaDAF",
        "outputId": "aa827e69-3a31-4af4-c44b-c3162a28b9bc"
      },
      "source": [
        "# Preprocess image\n",
        "pizza_img = load_and_prep_image(\"03-pizza-dad.jpeg\")\n",
        "pizza_img"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n",
              "array([[[ 73.625,  76.75 ,  67.125],\n",
              "        [114.   , 122.   , 101.   ],\n",
              "        [146.875, 151.875, 129.875],\n",
              "        ...,\n",
              "        [ 14.5  ,  17.5  ,  10.5  ],\n",
              "        [ 14.25 ,  19.25 ,  12.25 ],\n",
              "        [ 19.75 ,  22.75 ,  15.75 ]],\n",
              "\n",
              "       [[239.125, 243.625, 246.125],\n",
              "        [225.375, 232.125, 234.875],\n",
              "        [240.   , 245.   , 244.5  ],\n",
              "        ...,\n",
              "        [ 11.   ,  14.   ,   7.   ],\n",
              "        [ 20.   ,  23.   ,  16.   ],\n",
              "        [ 20.875,  25.875,  18.875]],\n",
              "\n",
              "       [[ 32.5  ,  34.5  ,  31.5  ],\n",
              "        [ 44.625,  44.5  ,  42.375],\n",
              "        [ 33.   ,  38.   ,  34.   ],\n",
              "        ...,\n",
              "        [  8.75 ,  13.25 ,   6.25 ],\n",
              "        [ 14.875,  17.875,  10.875],\n",
              "        [ 13.625,  20.625,  12.625]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 61.875,  40.875,  19.875],\n",
              "        [ 60.   ,  42.   ,  22.   ],\n",
              "        [ 61.   ,  43.   ,  21.   ],\n",
              "        ...,\n",
              "        [134.5  ,  96.125,  60.75 ],\n",
              "        [104.875,  69.375,  43.125],\n",
              "        [106.25 ,  75.25 ,  46.25 ]],\n",
              "\n",
              "       [[ 62.75 ,  44.75 ,  24.75 ],\n",
              "        [ 61.125,  43.125,  23.125],\n",
              "        [ 58.125,  40.125,  20.125],\n",
              "        ...,\n",
              "        [159.125, 111.125,  64.625],\n",
              "        [160.375, 112.375,  66.375],\n",
              "        [134.   ,  94.125,  56.75 ]],\n",
              "\n",
              "       [[ 59.625,  42.625,  22.625],\n",
              "        [ 61.75 ,  43.75 ,  22.5  ],\n",
              "        [ 59.25 ,  41.25 ,  21.25 ],\n",
              "        ...,\n",
              "        [161.5  , 113.5  ,  64.5  ],\n",
              "        [159.   , 108.   ,  63.   ],\n",
              "        [155.875, 104.875,  59.875]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81z-ynOlabav",
        "outputId": "594cd37a-a99e-447f-cb47-4410066cdeb8"
      },
      "source": [
        "# Make predictions\n",
        "pizza_expanded = tf.expand_dims(pizza_img, axis=0) # expand image dimensions (224, 224, 3) -> (1, 224, 224, 3)\n",
        "pred = model_1.predict(pizza_expanded)\n",
        "pred"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.6281351e-02, 5.3865446e-05, 8.9909328e-04, 4.0310339e-04,\n",
              "        5.2360929e-06, 1.0736467e-06, 9.8034036e-01, 6.3052826e-04,\n",
              "        2.6637688e-04, 1.1190677e-03]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHIoie0Faoin",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dcc89960-0db5-4d25-ad79-6cfd0a9ed4d4"
      },
      "source": [
        "# Check the predicted class\n",
        "class_names[tf.argmax(pred[0])]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'pizza'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0jm4Hzdc85u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da5649d0-ad19-40db-fa29-f5dc5abfc69b"
      },
      "source": [
        "# Save model_1\n",
        "model_1.save(\"efficientnet_model_1_10_classes\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: efficientnet_model_1_10_classes/assets\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}